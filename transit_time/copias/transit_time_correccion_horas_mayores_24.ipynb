{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "from datetime import datetime,date, time\n",
    "import timeit\n",
    "\n",
    "import scipy.stats as st\n",
    "#import statsmodels.api as sm\n",
    "from pyod.models.knn import KNN\n",
    "\n",
    "from joblib import dump, load\n",
    "import os\n",
    "from os import path\n",
    "#import shutil\n",
    "import logging\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tiempo de ejecucion\n",
    "start = timeit.default_timer()\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(fmt='%(asctime)s - %(levelname)s - %(message)s',datefmt='%d-%m-%Y')\n",
    "handler_log = logging.FileHandler(\"logging.log\")\n",
    "handler_log.setLevel(logging.DEBUG)\n",
    "handler_log.setFormatter(formatter)\n",
    "logger.addHandler(handler_log)\n",
    "\n",
    "logger.info(\"----Inicio de Estimacion Min Max----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path\n",
    "\n",
    "path_libs = \"libs/\"\n",
    "name_config = \"Input/config.xlsx\"\n",
    "\n",
    "# Nuevos archivos\n",
    "name_maestro_establecimientos = './input_bauti/maestro_establecimieto/maestro_establecimiento_areas.xlsx'\n",
    "name_transit_time  = \"./input_bauti/historico/df_historico.xlsx\"\n",
    "name_establecimientos = './input_bauti/coordenadas_campos/establecimientos_geolocalizados/establecimiento_geolocalizados_google.xlsx'\n",
    "\n",
    "# Archivos antiguos.\n",
    "#name_maestro_establecimientos = \"./Input_fijo/maestro_establecimientos.xlsx\"\n",
    "#name_establecimientos = \"Input/establecimientos.xlsx\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros del modelo a definir por configuracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    logger.info(\"Carga de Parametros\")\n",
    "    df_config = pd.read_excel(name_config)\n",
    "    vel_min = df_config.loc[0,\"vel_min\"].astype(int)\n",
    "    vel_max = df_config.loc[0,\"vel_max\"].astype(int)\n",
    "    vel = df_config.loc[0,\"vel_media\"].astype(int)\n",
    "    alpha = (df_config.loc[0,\"confianza\"]/100).astype(float)\n",
    "    hs_manejo = df_config.loc[0,\"hs_manejo\"].astype(int)\n",
    "    hs_descanso = df_config.loc[0,\"hs_descanso\"].astype(int)\n",
    "    segmentacion =  bool(1 if str(df_config.loc[0,\"segmentacion\"]).strip().lower() == \"si\"\n",
    "                            else 0)\n",
    "    logger.info(f\"KNN Segmentacion es: {segmentacion}\")\n",
    "except Exception as ex:\n",
    "    logger.warning(\"Error carga de parametros\")\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establecimientos y distancia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Carga de Datos\")\n",
    "try:\n",
    "    # Cargo TT a los distintos establecimientos.\n",
    "    df_consolidado = pd.read_excel(name_transit_time, parse_dates=False)\n",
    "    \n",
    "    # Carga Establecimientos.\n",
    "    df_distancias = pd.read_excel(name_establecimientos)\n",
    "    \n",
    "    # Maestro establecimientos.\n",
    "    df_maestro_establecimientos = pd.read_excel(name_maestro_establecimientos, dtype={\"latitud\":\"float\",\"longitud\":\"float\"})\n",
    "    \n",
    "except Exception as ex:\n",
    "    logger.warning(\"Error al cargar archivos\",exc_info=True)\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatteo de datos.\n",
    "try:\n",
    "    # Transit Time.\n",
    "    df_consolidado['tiempo_real'] = pd.to_timedelta(df_consolidado['tiempo_real'], errors='coerce')\n",
    "\n",
    "    # Mascara para eliminar registros con zona, establecimiento y georreferencias iguales.\n",
    "    mask_georreferencias_duplicadas = df_distancias[[\"zone\", \"establecimiento\",\"latitud\",\"longitud\"]].duplicated()\n",
    "\n",
    "    # Dropeo duplicados y reseteo indices.\n",
    "    df_distancias.drop(df_distancias[mask_georreferencias_duplicadas].index,inplace=True)\n",
    "    df_distancias = df_distancias.reset_index(drop=True)\n",
    "\n",
    "    # Me quedo con los duplicados\n",
    "    df_duplicado = df_distancias.loc[mask_georreferencias_duplicadas]\n",
    "\n",
    "    # Me quedo con el nombre original de los establecimientos.\n",
    "    establecimiento_upper = df_distancias.establecimiento.to_list()\n",
    "    \n",
    "    # Llevo todos los nombres de los establecimientos a minuscula.\n",
    "    df_consolidado.establecimiento = df_consolidado.establecimiento.str.strip().str.lower()\n",
    "    df_distancias.establecimiento = df_distancias.establecimiento.str.strip().str.lower()\n",
    "    df_maestro_establecimientos.establecimiento = df_maestro_establecimientos.establecimiento.str.strip().str.lower()\n",
    "    \n",
    "    # Dropeo duplicados del maestro de establecimientos.\n",
    "    df_maestro_establecimientos.establecimiento.drop_duplicates(inplace=True)\n",
    "except:\n",
    "    logger.warning(\"Error al cargar archivos\", exc_info=True)\n",
    "    quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecimientos que no se encuentran cargados en el maestro de establecimientos.\n",
    "mask_establecimientos_no_incluidos = df_distancias.establecimiento.isin(df_maestro_establecimientos.establecimiento)==False\n",
    "mask_zonas_no_incluidas = df_distancias.zone.isin(df_maestro_establecimientos.zona)==False\n",
    "mask_good_supplier_no_incluidas = df_distancias.good_supplier.isin(df_maestro_establecimientos.good_supplier)==False\n",
    "mask_area_no_incluidas = df_distancias.area.isin(df_maestro_establecimientos.area)==False\n",
    "\n",
    "mask_no_inlcuidos = mask_establecimientos_no_incluidos & mask_zonas_no_incluidas & mask_good_supplier_no_incluidas & mask_area_no_incluidas\n",
    "aux = df_distancias.loc[mask_no_inlcuidos, [\"zone\", \"establecimiento\", \"good_supplier\", \"area\", \"latitud\", \"longitud\"]].copy()\n",
    "\n",
    "# Si se encontraron establecimeintos no incluidos.\n",
    "if aux.shape[0]>0:\n",
    "    # Los concateno al maestro de establecimientos.\n",
    "    df_maestro_establecimientos = pd.concat ([df_maestro_establecimientos, aux])\n",
    "    df_maestro_establecimientos =  df_maestro_establecimientos.reset_index(drop=True)\n",
    "df_maestro_establecimientos[\"Duplicado\"] = 0\n",
    "\n",
    "aux = df_distancias [[\"zone\", \"establecimiento\", \"good_supplier\", \"area\", \"latitud\", \"longitud\"]].copy()\n",
    "# Renombro para que coincidan los campos\n",
    "aux.rename(columns={'zone' : 'zona'}, inplace=True)\n",
    "\n",
    "aux = df_maestro_establecimientos.merge(aux,\"left\",on=[\"zona\",\"establecimiento\", \"good_supplier\", \"area\"])\n",
    "\n",
    "aux.dropna(subset=[\"latitud_y\",\"longitud_y\"], inplace=True)\n",
    "\n",
    "aux [\"Duplicado\"] = aux.apply(lambda row: 1 if ((round(row.latitud_x,9) != round(row.latitud_y,9))|\n",
    "                                        (round(row.longitud_x,9) != round(row.longitud_y,9))) else 0,axis=1)\n",
    "\n",
    "aux = aux [[\"zona\", \"establecimiento\", \"good_supplier\", \"area\",\"latitud_y\",\"longitud_y\",\"Duplicado\"]]\n",
    "aux.rename(columns={\"latitud_y\":\"latitud\",\"longitud_y\":\"longitud\"},inplace=True)\n",
    "\n",
    "# Me quedo con los registros que tienen un error en la latitud o longitud.\n",
    "aux = aux.loc[aux[\"Duplicado\"] == 1]\n",
    "# Si hay registros con errores.\n",
    "if aux.shape[0]>0:\n",
    "    # Los concateno al maestro de materiales.\n",
    "    df_maestro_establecimientos = pd.concat ([df_maestro_establecimientos, aux]).reset_index(drop=True)\n",
    "\n",
    "df_maestro_establecimientos.loc[df_maestro_establecimientos.Duplicado==1,\"Duplicado\"] = \"Diferencia geolocalizacion\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_timestamp (row):\n",
    "    formato = '%d/%m/%Y %H:%M'\n",
    "    \n",
    "    anio = row['a√±o']\n",
    "    dia_mes_inicio = row['start_dt'].split(' ')\n",
    "    dia_mes_final = row['end_dt'].split(' ')\n",
    "    \n",
    "    start_date = dia_mes_inicio[0] + '/' + str(anio) + ' ' + dia_mes_inicio[-1]\n",
    "    end_date = dia_mes_final[0] + '/' + str(anio) + ' ' + dia_mes_final[-1]\n",
    "    \n",
    "    format_start_date = datetime.strptime(start_date, formato)\n",
    "    format_end_date = datetime.strptime(end_date, formato)\n",
    "    \n",
    "    tiempo_real = format_end_date - format_start_date\n",
    "    tiempo_real_secs = tiempo_real.seconds\n",
    "    \n",
    "    hours, remainder = divmod(tiempo_real_secs, 3600)  # 3600 seconds in an hour\n",
    "    minutes, seconds = divmod(remainder, 60)   # 60 seconds in a minute\n",
    "    \n",
    "    return time(hours, minutes, seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_consolidado['tiempo_real'] = df_consolidado.apply(lambda row: convert_timestamp(row), axis=1)\n",
    "#df_consolidado['tiempo_real'] = pd.to_timedelta(df_consolidado['tiempo_real']).dt.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de modelo de Segmentacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de segmentar me fijo si el cliente envio ya dividido por subzonas.\n",
    "# Si la zona se encuentra dividida por subzonas procedo a eliminarlas antes de segmentar.\n",
    "if segmentacion:\n",
    "    df_consolidado.subZone = df_consolidado.subZone.str.replace(r'\\d*','', regex=True)\n",
    "    df_distancias.zone = df_distancias.zone.str.replace(r'\\d*','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino funcion para obtener el tiempo de descanso en cada viaje.\n",
    "# se calcula si la distancia dividida la velocidad media de 60 km supera las horas de manejo\n",
    "# si supera las horas de manejo se divide la distancia por la velocidad de manejo permitida (3 hs)\n",
    "# luego se multiplica por 60 para obtener el resultado en minutos y se divide por el tiempo de descanso en hs\n",
    "# obteniendo los minutos de descanso para le viaje.\n",
    "def duracion_descanso(row):\n",
    "    # Obtengo las hs de viaje.\n",
    "    hs_viaje = (row['distancia'] / vel)\n",
    "    \n",
    "    # Obtengo la cantidad de descansos necesarios para el viaje.\n",
    "    cant_descansos = hs_viaje / hs_manejo\n",
    "    # Obtengo los minutos de descanso en el viaje.\n",
    "    min_descanso = cant_descansos * hs_descanso * 60 \n",
    "    \n",
    "    # Obtengo los minutos de viaje.\n",
    "    min_viaje = hs_viaje * 60\n",
    "    # Obtengo los min de manejo que se permiten.\n",
    "    min_manejo = hs_manejo * 60\n",
    "    \n",
    "    # Si el viaje dura mas que las horas estipuladas de manejo.\n",
    "    if min_viaje > min_manejo:\n",
    "        return min_descanso\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_distancias [\"duracion_cdescanso\"] = df_distancias.apply(lambda row: duracion_descanso(row),axis=1)\n",
    "    \n",
    "    # Obtengo la duracion del viaje con desanso incluido.\n",
    "    df_distancias [\"duracion_min_cdescanso\"] = df_distancias[\"duracion_cdescanso\"] + df_distancias[\"duracion_min\"]\n",
    "    \n",
    "    # Selecciono los campos necesarios para la clusterizacion\n",
    "    df_cluster = df_distancias[['distancia_value_mts','duracion_min_cdescanso']].copy()\n",
    "    \n",
    "    # Carga del modelo de clusterizacion\n",
    "    kmeans = load(path.join(path_libs,\"cluster_establecimientos.joblibs\"))\n",
    "    # Predigo y obtengo grupos.\n",
    "    group = kmeans.predict(df_cluster)\n",
    "    df_distancias [\"group\"] = group\n",
    "    \n",
    "    #Segementacion de los establecimientos mediante el modelo de clustering\n",
    "    df_distancias[\"zone_group\"] = \"\"\n",
    "    \n",
    "    zones = df_distancias.zone.value_counts().index.to_list()\n",
    "    for zone in zones:\n",
    "        groups = df_distancias.loc[df_distancias.zone == zone,\"group\"].value_counts().index.to_list()\n",
    "        groups.sort()\n",
    "        df_distancias.loc[df_distancias.zone==zone,\"zone_group\"] = df_distancias.loc[df_distancias.zone==zone].apply(lambda x: zone + str(groups.index(x.group)+1) if len(groups) > 1 else x.zone, axis=1) \n",
    "\n",
    "    resumen_segmentacion = df_distancias.pivot_table(values=[\"distancia\",\"duracion_min_cdescanso\"], index=\"group\", aggfunc=[\"min\",\"max\"])\n",
    "    resumen_segmentacion.columns = resumen_segmentacion.columns.to_flat_index()\n",
    "    resumen_segmentacion.columns = [\"Distancia Minima\",\"Duracion Minima\",\"Distancia Maxima\",\"Duracion Maxima\"]\n",
    "    resumen_segmentacion = resumen_segmentacion.sort_values(by=\"Distancia Minima\").reset_index(drop=True)\n",
    "    resumen_segmentacion.reset_index(inplace=True)\n",
    "    resumen_segmentacion.rename(columns={\"index\":\"Grupo\"},inplace = True)\n",
    "    resumen_segmentacion[\"Grupo\"] +=1\n",
    "    resumen_segmentacion = resumen_segmentacion [[\"Grupo\",\"Distancia Minima\",\"Distancia Maxima\",\"Duracion Minima\",\"Duracion Maxima\"]]   \n",
    "except Exception as ex:\n",
    "    logger.warning(\"Error al cargar modelo de segmentacion\",exc_info=True)\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voy a agregar la informacion de los establecimientos a la informacion de los viajes.\n",
    "\n",
    "# Me quedo unicamente con los establecimientos que estan en df_distancias.\n",
    "establecimientos_considerar = df_distancias['establecimiento'].unique().tolist()\n",
    "#df_consolidado = df_consolidado.loc[df_consolidado['establecimiento'].isin(establecimientos_considerar),:]\n",
    "\n",
    "# Esta bien si despues de este merge hay mas establecimiento\n",
    "df_consolidado = df_consolidado.merge(df_distancias, how=\"left\", on=['establecimiento'])\n",
    "\n",
    "#Mantiene la zona de segmentacion de cluster si es True caso contrario mantiene las zonas del cliente\n",
    "if (segmentacion==True):\n",
    "    df_consolidado.subZone = df_consolidado.zone_group\n",
    "    df_distancias.zone =  df_distancias.zone_group\n",
    "else:\n",
    "    df_consolidado.subZone = df_consolidado.zone #valores segun el input - \"coordenadas_campos\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesado de Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Timedelta' object has no attribute 'hour'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m df_consolidado\u001b[39m.\u001b[39mdrop(df_consolidado\u001b[39m.\u001b[39mloc[df_consolidado\u001b[39m.\u001b[39mtiempo_real\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mtype\u001b[39m(x) \u001b[39mis\u001b[39;00m \u001b[39mfloat\u001b[39m)]\u001b[39m.\u001b[39mindex, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[39m#tiempo real en horas\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df_consolidado[\u001b[39m\"\u001b[39m\u001b[39mtiempo_real\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_consolidado\u001b[39m.\u001b[39;49mtiempo_real\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: ( ((x\u001b[39m.\u001b[39;49mday\u001b[39m*\u001b[39;49m\u001b[39m24\u001b[39;49m)\u001b[39m*\u001b[39;49m\u001b[39m60\u001b[39;49m) \u001b[39m+\u001b[39;49m (x\u001b[39m.\u001b[39;49mhour\u001b[39m*\u001b[39;49m\u001b[39m60\u001b[39;49m) \u001b[39m+\u001b[39;49m(x\u001b[39m.\u001b[39;49mminute)  ) \n\u001b[0;32m      6\u001b[0m                                                                  \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(x,datetime)  \u001b[39melse\u001b[39;49;00m ((x\u001b[39m.\u001b[39;49mhour\u001b[39m*\u001b[39;49m\u001b[39m60\u001b[39;49m) \u001b[39m+\u001b[39;49m (x\u001b[39m.\u001b[39;49mminute)))\n\u001b[0;32m      8\u001b[0m df_consolidado[\u001b[39m\"\u001b[39m\u001b[39mtiempo_real\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_consolidado[\u001b[39m\"\u001b[39m\u001b[39mtiempo_real\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n\u001b[0;32m      9\u001b[0m df_consolidado \u001b[39m=\u001b[39m df_consolidado[[\u001b[39m\"\u001b[39m\u001b[39msubZone\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mestablecimiento\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgood_supplier\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39marea\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdistancia\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mtiempo_real\u001b[39m\u001b[39m\"\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\TALIGENT\\anaconda3\\envs\\transit_time_bayer\\lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\Users\\TALIGENT\\anaconda3\\envs\\transit_time_bayer\\lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\TALIGENT\\anaconda3\\envs\\transit_time_bayer\\lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\TALIGENT\\anaconda3\\envs\\transit_time_bayer\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[34], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m df_consolidado\u001b[39m.\u001b[39mdrop(df_consolidado\u001b[39m.\u001b[39mloc[df_consolidado\u001b[39m.\u001b[39mtiempo_real\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39mtype\u001b[39m(x) \u001b[39mis\u001b[39;00m \u001b[39mfloat\u001b[39m)]\u001b[39m.\u001b[39mindex, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[39m#tiempo real en horas\u001b[39;00m\n\u001b[0;32m      5\u001b[0m df_consolidado[\u001b[39m\"\u001b[39m\u001b[39mtiempo_real\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_consolidado\u001b[39m.\u001b[39mtiempo_real\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: ( ((x\u001b[39m.\u001b[39mday\u001b[39m*\u001b[39m\u001b[39m24\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m60\u001b[39m) \u001b[39m+\u001b[39m (x\u001b[39m.\u001b[39mhour\u001b[39m*\u001b[39m\u001b[39m60\u001b[39m) \u001b[39m+\u001b[39m(x\u001b[39m.\u001b[39mminute)  ) \n\u001b[1;32m----> 6\u001b[0m                                                                  \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x,datetime)  \u001b[39melse\u001b[39;00m ((x\u001b[39m.\u001b[39;49mhour\u001b[39m*\u001b[39m\u001b[39m60\u001b[39m) \u001b[39m+\u001b[39m (x\u001b[39m.\u001b[39mminute)))\n\u001b[0;32m      8\u001b[0m df_consolidado[\u001b[39m\"\u001b[39m\u001b[39mtiempo_real\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df_consolidado[\u001b[39m\"\u001b[39m\u001b[39mtiempo_real\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mfloat\u001b[39m)\n\u001b[0;32m      9\u001b[0m df_consolidado \u001b[39m=\u001b[39m df_consolidado[[\u001b[39m\"\u001b[39m\u001b[39msubZone\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mestablecimiento\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgood_supplier\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39marea\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdistancia\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mtiempo_real\u001b[39m\u001b[39m\"\u001b[39m]]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Timedelta' object has no attribute 'hour'"
     ]
    }
   ],
   "source": [
    "df_consolidado.tiempo_real.dropna(axis=0,inplace=True)\n",
    "df_consolidado.drop(df_consolidado.loc[df_consolidado.tiempo_real.apply(lambda x: type(x) is float)].index, axis=0,inplace=True)\n",
    "\n",
    "#tiempo real en horas\n",
    "df_consolidado[\"tiempo_real\"] = df_consolidado.tiempo_real.apply(lambda x: ( ((x.day*24)*60) + (x.hour*60) +(x.minute)  ) \n",
    "                                                                 if isinstance(x,datetime)  else ((x.hour*60) + (x.minute)))\n",
    "\n",
    "df_consolidado[\"tiempo_real\"] = df_consolidado[\"tiempo_real\"].astype(float)\n",
    "df_consolidado = df_consolidado[[\"subZone\",\"establecimiento\", \"good_supplier\", \"area\", \"distancia\",\"tiempo_real\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar outliers\n",
    "logger.info(\"Eliminacion de outliers\")\n",
    "#velocidades para eliminar  outliers\n",
    "min, max = 30,110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculo de la Duracion media, minima y maxima\n",
    "\n",
    "df_consolidado[\"duracion_cdescanso\"] = df_consolidado.apply(lambda x: ((x.distancia/vel)*60),\n",
    "                                                            axis=1)\n",
    "df_consolidado[\"duracion_min_cdescanso\"] = df_consolidado.apply(lambda x: ((x.distancia/max)*60),\n",
    "                                                            axis=1)\n",
    "df_consolidado[\"duracion_max_cdescanso\"] = df_consolidado.apply(lambda x: ((x.distancia/min)*60),\n",
    "                                                            axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suma de horas de descanso si la duracion del viaje es mayor que la establecida para horas de manejo\n",
    "df_consolidado[\"duracion_cdescanso\"] += df_consolidado.apply(lambda x:  ((x.duracion_cdescanso)/hs_manejo)*hs_descanso\n",
    "                    if (x.duracion_cdescanso > (hs_manejo*60)) else 0, axis=1)\n",
    "\n",
    "df_consolidado[\"duracion_min_cdescanso\"] += df_consolidado.apply(lambda x:  ((x.duracion_min_cdescanso)/hs_manejo)*hs_descanso\n",
    "                    if (x.duracion_cdescanso > (hs_manejo*60)) else 0 ,  axis=1)\n",
    "\n",
    "df_consolidado[\"duracion_max_cdescanso\"] += df_consolidado.apply(lambda x:  ((x.duracion_max_cdescanso)/hs_manejo)*hs_descanso\n",
    "                    if (x.duracion_cdescanso > (hs_manejo*60)) else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrego una holgura de media hora para los valores que tienen una ditancia menor a la velocidad min \n",
    "#esto es porque al dividir por un numero mas grande se hace peque√±a la duracion min\n",
    "#y la duracion maxima tambien es se hace peque√±a\n",
    "df_consolidado[\"duracion_max_cdescanso\"] += df_consolidado.apply(lambda x: 30 if x.distancia <= vel_min else 0 ,  axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separo los outliers encontrados\n",
    "df_outliers = df_consolidado.loc[(df_consolidado.tiempo_real > df_consolidado.duracion_max_cdescanso ) ]\n",
    "df_outliers = pd.concat( [df_outliers,df_consolidado.loc[(df_consolidado.tiempo_real) < (df_consolidado.duracion_min_cdescanso)]])    \n",
    "\n",
    "df_consolidado.drop(index=df_outliers.index, inplace=True)\n",
    "df_consolidado.dropna(inplace=True)\n",
    "\n",
    "df_modelo = df_consolidado [[\"distancia\",\"tiempo_real\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminando outliers mediante el analisis de todos los datos KNN\n",
    "local_outlier = KNN(contamination=0.03)\n",
    "local_outlier = local_outlier.fit(df_modelo)\n",
    "y_pred_outlier = local_outlier.predict(df_modelo)\n",
    "df_consolidado[\"out\"] = y_pred_outlier\n",
    "drop = df_consolidado.loc[df_consolidado.out == 1].index\n",
    "\n",
    "df_consolidado.drop(drop,inplace = True)\n",
    "df_consolidado.drop(\"out\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intervalos de Confianza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools, funciones de utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ic_to_horas (minutos):\n",
    "    \"\"\" \n",
    "    Descripcion\n",
    "    --------------------------------\n",
    "    Formatea los minutos \n",
    "    calculados para una zona en str\n",
    "    de HH:mm ry rendondea los\n",
    "    resultados\n",
    "    \n",
    "    Parametros\n",
    "    --------------------------------\n",
    "    minutos (float) = cantidad de\n",
    "    minutos establecidos para una \n",
    "    ventana de transit time.\n",
    "    \"\"\"\n",
    "    horas = int(divmod(minutos,60)[0])\n",
    "    minutos = int(divmod(minutos,60)[1])\n",
    "    horas_s = f\"{horas}\"\n",
    "    minutos_s = f\"{minutos}\"\n",
    "    if (minutos <= 14):\n",
    "        minutos_s = f\"00\"\n",
    "    if ( 15 <= minutos < 45):\n",
    "        minutos_s = f\"30\"\n",
    "    if ( 45 <= minutos < 60):\n",
    "        minutos_s = f\"00\"\n",
    "        horas += 1\n",
    "        horas_s = f\"{horas}\"      \n",
    "    if(horas < 10):\n",
    "        horas_s = f\"0{horas}\"\n",
    "    tiempo = f\"{horas_s}:{minutos_s}\"\n",
    "    return tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_to_horas (minutos):\n",
    "    \"\"\"\n",
    "    Descripcion\n",
    "    --------------------------------\n",
    "    Formatea los minutos \n",
    "    calculados en un str tipo\n",
    "    HH:mm \n",
    "    \n",
    "    Parametros\n",
    "    --------------------------------\n",
    "    minutos (float) = cantidad de\n",
    "    minutos\n",
    "    \"\"\"\n",
    "    horas = int(divmod(minutos,60)[0])\n",
    "    minutos = int(divmod(minutos,60)[1])\n",
    "    horas_s = f\"{horas}\"\n",
    "    minutos_s = f\"{minutos}\"\n",
    "    if(horas < 10):\n",
    "        horas_s = f\"0{horas}\"\n",
    "    if (minutos < 10):\n",
    "        minutos_s = f\"0{minutos}\"\n",
    "    tiempo = f\"{horas_s}:{minutos_s}\"\n",
    "    return tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hs_descansos (minutos):\n",
    "    \"\"\"\n",
    "    Descripcion\n",
    "    --------------------------------\n",
    "    Formatea los minutos \n",
    "    calculados en un str tipo\n",
    "    HH:mm \n",
    "    \n",
    "    Parametros\n",
    "    --------------------------------\n",
    "    minutos (float) = cantidad de\n",
    "    minutos\n",
    "    \"\"\"\n",
    "    horas = int(divmod(minutos,60)[0])\n",
    "    minutos = int(divmod(minutos,60)[1])\n",
    "    horas_s = f\"{horas}\"\n",
    "    minutos_s = f\"{minutos}\"\n",
    "    if (minutos == 0):\n",
    "        minutos_s = \"00\"\n",
    "    if ( 0 < minutos <= 30):\n",
    "        minutos_s = \"30\"\n",
    "    if ( 30 < minutos <= 59):\n",
    "        minutos_s = \"00\"\n",
    "        horas += 1\n",
    "    if(horas < 10):\n",
    "        horas_s = f\"0{horas}\"\n",
    "        \n",
    "    tiempo = f\"{horas_s}:{minutos_s}\"\n",
    "    return tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descansos, los descansos establecidos para los choferes corresponde actualmente a\n",
    "# una hora de descanso cada 3 hs de viaje\n",
    "\n",
    "# Esta funcion esta comentada ya que este paso ya se realizo al momento de preparar \n",
    "# los datos para el modelo de segmentacion.\n",
    "'''\n",
    "df_distancias [\"duracion_cdescanso\"] = df_distancias.apply(lambda x: \n",
    "                                                           ((x.distancia/vel)*60)/((hs_manejo))*hs_descanso\n",
    "                                                           if ((x.distancia/vel)*60) > ((hs_manejo)*60)\n",
    "                                                           else 0,\n",
    "                                                           axis=1)\n",
    "'''\n",
    "logger.info(\"Calculo Descansos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Horas de descanso a Horas\n",
    "# pasamos los descansos expresados en minutos a horas\n",
    "df_distancias [\"duracion_cdescanso\"] = df_distancias.duracion_cdescanso.apply(lambda x: hs_descansos (x) if x > 0 else \"00:00\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intervalos de Confianza Estadistico x Subzona\n",
    "#las velocidades medias y maximas estadisitcas se calculan apartir de la distribucion de probabilidad de la muestra\n",
    "# se agrupan los tiempos de todas los establecimientos que conforman la zona\n",
    "# se genera su distribucion de probabilidad\n",
    "# y se calcula el min y max segun un intervalo de confianza en el cual agrupa los datos alrededor de la media\n",
    "logger.info(\"Calculos de intervalos de confianza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculo de Intervalos de Confianza por Subzona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a considerar por un lado los establecimientos de fundadora y por el otro los de comercial.\n",
    "\n",
    "# Para df_distancias\n",
    "mask_establecimientos_fundadora_distancias = df_distancias['area'] == 'fundadora'\n",
    "df_distancias_comercial = df_distancias.loc[ ~ mask_establecimientos_fundadora_distancias, : ]\n",
    "df_distancias_fundadora = df_distancias.loc[ mask_establecimientos_fundadora_distancias, : ]\n",
    "\n",
    "# Para df_consolidado\n",
    "mask_establecimientos_fundadora_consolidado = df_consolidado['area'] == 'fundadora'\n",
    "df_consolidado_comercial = df_consolidado.loc[ ~ mask_establecimientos_fundadora_consolidado, : ]\n",
    "df_consolidado_fundadora = df_consolidado.loc[ mask_establecimientos_fundadora_consolidado, : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los agrego a un diccionario para poder acceder a ellos mediante un loop.\n",
    "df_distancias_dict ={'0' : df_distancias_comercial, '1' : df_distancias_fundadora}\n",
    "df_consolidado_dict = {'0' : df_consolidado_comercial, '1' : df_consolidado_fundadora}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Creo un Diccionario para almacenar el resultado de esta ejecucion.\n",
    "    df_subzonas_dict = {}\n",
    "    \n",
    "    for i in range(0,2):\n",
    "        # Cargo DFs.\n",
    "        df_distancias_loop = df_distancias_dict[str(i)].copy()\n",
    "        df_consolidado_loop = df_consolidado_dict[str(i)].copy()\n",
    "        \n",
    "        subzone =  df_consolidado_loop.subZone.value_counts().index\n",
    "        \n",
    "        for zone in subzone:\n",
    "            datos = df_consolidado_loop.loc[df_consolidado_loop.subZone == zone,\"tiempo_real\"]\n",
    "            min, max = st.norm.interval (alpha , loc = np.mean(datos), scale = datos.std()) \n",
    "            df_consolidado_loop.loc[df_consolidado_loop.subZone == zone,\"ic_min\"] = min\n",
    "            df_consolidado_loop.loc[df_consolidado_loop.subZone == zone,\"ic_max\"] = max\n",
    "            if min < 14:\n",
    "                min =  df_consolidado_loop.loc[df_consolidado_loop.subZone == zone,\"tiempo_real\"].quantile(0.2) \n",
    "                df_consolidado_loop.loc[df_consolidado_loop.subZone == zone,\"ic_min\"] = min\n",
    "\n",
    "        df_consolidado_loop[[\"ic_min\",\"ic_max\"]] = df_consolidado_loop[[\"ic_min\",\"ic_max\"]].round()\n",
    "        df_consolidado_loop[[\"ic_min\",\"ic_max\"]] = df_consolidado_loop[[\"ic_min\",\"ic_max\"]].astype(int)\n",
    "        \n",
    "        df_consolidado_loop[[\"ic_min\",\"ic_max\"]]\n",
    "        \n",
    "        df_consolidado_loop [\"ic_min_hs\"] = df_consolidado_loop.ic_min.apply(lambda x:  ic_to_horas(x))\n",
    "        df_consolidado_loop [\"ic_max_hs\"] = df_consolidado_loop.ic_max.apply(lambda x:   ic_to_horas(x))\n",
    "        \n",
    "        df_consolidado_loop [[\"subZone\",\"ic_min_hs\", \"ic_max_hs\"]]\n",
    "        \n",
    "        df_subzonas_loop = df_consolidado_loop.pivot_table(values=[\"ic_min\",\"ic_max\"], index=[\"subZone\",\"area\"],aggfunc=\"mean\").reset_index()\n",
    "        \n",
    "        df_subzonas_loop [\"ic_min_hs\"] = df_subzonas_loop.ic_min.apply(lambda x:  ic_to_horas(x))\n",
    "        df_subzonas_loop [\"ic_max_hs\"] = df_subzonas_loop.ic_max.apply(lambda x:  ic_to_horas(x))\n",
    "        \n",
    "        confianza = df_consolidado_loop.pivot_table(values=\"establecimiento\",index=[\"subZone\",\"area\"] ,aggfunc=\"count\" )\n",
    "        \n",
    "        confianza.columns = confianza.columns.to_flat_index()\n",
    "        \n",
    "        confianza = confianza.reset_index()\n",
    "        \n",
    "        confianza.columns = [\"subZone\", \"area\", \"conteo\"]\n",
    "        confianza[\"Confianza\"] = confianza.apply (lambda x: \"Si\" if x.conteo > 30 else \"No\" ,axis = 1)\n",
    "        \n",
    "        df_subzonas_loop = df_subzonas_loop.merge(confianza , \"left\", on=[\"subZone\", \"area\"])\n",
    "        \n",
    "        aux = df_distancias_loop.pivot_table(values=\"distancia\",index=[\"zone\", \"area\"] )\n",
    "        \n",
    "        aux.columns = aux.columns.to_flat_index()\n",
    "        aux.columns = [\"distancia\"]\n",
    "        aux = aux.reset_index()\n",
    "        aux.drop(\"distancia\",axis=1,inplace=True)\n",
    "        \n",
    "        df_subzonas_loop = aux.merge(df_subzonas_loop,\"left\",left_on=[\"zone\",\"area\"],right_on=[\"subZone\",\"area\"])\n",
    "        df_subzonas_loop [\"subZone\"] = df_subzonas_loop.zone\n",
    "        \n",
    "        df_subzonas_loop.Confianza.fillna(\"Nuevo\", inplace=True)\n",
    "        df_subzonas_loop.fillna(\"-\",inplace=True)\n",
    "        \n",
    "        # Agrego el resultado de esta ejecucion del loop en el diccionario.\n",
    "        df_subzonas_dict[str(i)] = df_subzonas_loop\n",
    "except Exception as ex:\n",
    "    logger.warning(\"Error al calcular min max zonas estadistico\", exc_info=True)\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intervalos de Confianza Estadistico x Establecimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculo de Intervalos de Confianza por Establecimiento\n",
    "try:\n",
    "    # Creo un Diccionario para almacenar el resultado de esta ejecucion.\n",
    "    df_establecimiento_dict = {}\n",
    "\n",
    "    for i in range(0,2):\n",
    "        # Cargo DFs.\n",
    "        df_distancias_loop = df_distancias_dict[str(i)].copy()\n",
    "        df_consolidado_loop = df_consolidado_dict[str(i)].copy()\n",
    "        \n",
    "        establecimientos = df_distancias_loop.establecimiento.value_counts().index\n",
    "        \n",
    "        for zone in establecimientos:\n",
    "            datos = df_consolidado_loop.loc[df_consolidado_loop.establecimiento == zone,\"tiempo_real\"]\n",
    "            min, max = st.norm.interval (alpha , loc = np.mean(datos), scale = datos.std()) \n",
    "            df_consolidado_loop.loc[df_consolidado_loop.establecimiento == zone,\"ic_min_establecimiento\"] = min\n",
    "            df_consolidado_loop.loc[df_consolidado_loop.establecimiento == zone,\"ic_max_establecimiento\"] = max \n",
    "            \n",
    "        df_consolidado_loop [\"ic_esta_min_hs\"] = df_consolidado_loop.ic_min_establecimiento.apply(lambda x:  ic_to_horas(x) )\n",
    "        df_consolidado_loop [\"ic_esta_max_hs\"] = df_consolidado_loop.ic_max_establecimiento.apply(lambda x:   ic_to_horas(x) )\n",
    "        \n",
    "        df_establecimiento_loop = df_consolidado_loop.pivot_table(values=[\"ic_min_establecimiento\",\"ic_max_establecimiento\",\"tiempo_real\"], \n",
    "                                                        index=[\"establecimiento\", \"subZone\", \"area\", \"good_supplier\"],\n",
    "                                                        aggfunc = {\n",
    "                                                            \"ic_min_establecimiento\" : \"mean\",\n",
    "                                                            \"ic_max_establecimiento\" : \"mean\",\n",
    "                                                            \"tiempo_real\" : \"count\"\n",
    "                                                        } ).reset_index()\n",
    "        \n",
    "        df_establecimiento_loop [\"ic_min_hs\"] = df_establecimiento_loop.ic_min_establecimiento.apply(lambda x:  min_to_horas(x))\n",
    "        df_establecimiento_loop [\"ic_max_hs\"] = df_establecimiento_loop.ic_max_establecimiento.apply(lambda x:  min_to_horas(x))\n",
    "        \n",
    "        df_establecimiento_loop = df_establecimiento_loop [[\"subZone\", \"establecimiento\",\"good_supplier\", \"area\", \"ic_min_hs\",\"ic_max_hs\",\"tiempo_real\"]].copy()\n",
    "        \n",
    "        df_establecimiento_loop [\"Confianza\"] = df_establecimiento_loop.tiempo_real.apply(lambda x: \"Si\" if x > 30 else \"No\")\n",
    "        \n",
    "        df_establecimiento_loop = df_distancias_loop.merge(\n",
    "            df_establecimiento_loop,\n",
    "            how=\"left\",\n",
    "            left_on = ['zone', 'establecimiento', 'good_supplier', 'area'],\n",
    "            right_on = ['subZone', 'establecimiento', 'good_supplier', 'area']\n",
    "            )\n",
    "        \n",
    "        df_establecimiento_loop = df_establecimiento_loop[[\"subZone\", \"establecimiento\",\"good_supplier\", \"area\", \"ic_min_hs\",\"ic_max_hs\",\"Confianza\"]]\n",
    "        \n",
    "        df_establecimiento_loop.ic_min_hs.fillna(\"-\",inplace=True)\n",
    "        df_establecimiento_loop.ic_max_hs.fillna(\"-\",inplace=True)\n",
    "        df_establecimiento_loop.Confianza.fillna(\"Nuevo\",inplace=True)\n",
    "        \n",
    "        df_distancias_loop_merge_descanso = df_distancias_loop[['establecimiento','duracion_cdescanso']]\n",
    "        df_establecimiento_loop = df_establecimiento_loop.merge(df_distancias_loop_merge_descanso, how='left', on='establecimiento')\n",
    "        \n",
    "        df_establecimiento_loop.columns = [\"Zona\", \"Establecimiento\",\"Good Supplier\", \"Area\", \"T.T Min\", \"T.T Max\",\"Confianza\",\"Descanso\"]\n",
    "        \n",
    "        # Agrego el resultado de esta ejecucion del loop en el diccionario.\n",
    "        df_establecimiento_dict[str(i)] = df_establecimiento_loop\n",
    "        \n",
    "except Exception as ex:\n",
    "    logger.warn(\"Error al calcular los min max por establecimiento estadistico\", exc_info=True)\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intervalo de confianza algoritmico Establecimiento.\n",
    "try:\n",
    "    # Creo un Diccionario para almacenar el resultado de esta ejecucion.\n",
    "    df_subzonas_2_dict = {}\n",
    "\n",
    "    for i in range(0,2):\n",
    "        # Cargos DFs.\n",
    "        df_distancias_loop = df_distancias_dict[str(i)].copy()\n",
    "        df_establecimiento_loop = df_establecimiento_dict[str(i)].copy()\n",
    "        \n",
    "        df_subzonas_2_loop = df_distancias_loop[[\"zone\", \"establecimiento\", \"good_supplier\", \"area\",\"distancia\",\"duracion_cdescanso\"]].copy()\n",
    "        \n",
    "        df_subzonas_2_loop[\"duracion_min\"] = ((df_subzonas_2_loop[\"distancia\"] / vel_max) * 60)\n",
    "        df_subzonas_2_loop[\"duracion_min\"] += df_subzonas_2_loop.apply(lambda x:  ((x[\"duracion_min\"])/hs_manejo)*hs_descanso\n",
    "                            if (x[\"distancia\"] > (hs_manejo*60)) \n",
    "                            else x[\"duracion_min\"], axis=1)\n",
    "        \n",
    "        df_subzonas_2_loop[\"duracion_max\"] = ((df_subzonas_2_loop[\"distancia\"]/vel_min)*60)\n",
    "        df_subzonas_2_loop[\"duracion_max\"] += df_subzonas_2_loop.apply(lambda x:  ((x[\"duracion_max\"])/hs_manejo)*hs_descanso\n",
    "                            if (x[\"distancia\"] > (hs_manejo*60))\n",
    "                            else x[\"duracion_max\"],\n",
    "                            axis=1)\n",
    "        \n",
    "        df_subzonas_2_loop [\"ic_hs_min\"] = df_subzonas_2_loop[\"duracion_min\"].apply(lambda x:  min_to_horas(x) )\n",
    "        df_subzonas_2_loop [\"ic_hs_max\"] = df_subzonas_2_loop[\"duracion_max\"].apply(lambda x:   min_to_horas(x) )\n",
    "        \n",
    "        df_subzonas_2_loop = df_subzonas_2_loop  [[\"zone\", \"establecimiento\", \"good_supplier\", \"area\",\"ic_hs_min\", \"ic_hs_max\",\"duracion_cdescanso\"]]\n",
    "        df_subzonas_2_loop.columns = [\"Zona\", \"Establecimiento\", \"Good Supplier\", \"Area\",\"T.T Min\",\"T.T Max\",\"Descanso\"]\n",
    "        \n",
    "        \n",
    "        # Agrego el resultado de esta ejecucion del loop en el diccionario.\n",
    "        df_subzonas_2_dict[str(i)] = df_subzonas_2_loop\n",
    "\n",
    "except Exception as ex:\n",
    "    logger.warning(\"Error al calcular min max algoritmico por establecimiento\")\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intevalo de Confianza algoritmico por zona\n",
    "try:\n",
    "    # Creo un Diccionario para almacenar el resultado de esta ejecucion.\n",
    "    df_subzonas_algoritmico_dict = {}\n",
    "        \n",
    "    for i in range(0,2):\n",
    "        # Cargos DFs.\n",
    "        df_distancias_loop = df_distancias_dict[str(i)].copy()\n",
    "        \n",
    "        subzonas_algoritmico_loop =  df_distancias_loop.pivot_table(\n",
    "            values=\"distancia\", \n",
    "            index=[\"zone\", 'area'],\n",
    "            aggfunc=[\"min\",\"max\"]\n",
    "        )\n",
    "        \n",
    "        subzonas_algoritmico_loop.columns = subzonas_algoritmico_loop.columns.to_flat_index()\n",
    "        subzonas_algoritmico_loop = subzonas_algoritmico_loop.reset_index()\n",
    "        subzonas_algoritmico_loop.columns = [\"zone\", \"area\", \"distancia_min\",\"distancia_max\"]\n",
    "        \n",
    "        subzonas_algoritmico_loop[\"duracion_min\"] = ((subzonas_algoritmico_loop[\"distancia_min\"] / vel_max)*60)\n",
    "        subzonas_algoritmico_loop[\"duracion_min\"] += subzonas_algoritmico_loop.apply(lambda x:  ((x[\"duracion_min\"])/hs_manejo)*hs_descanso\n",
    "                                                                        if (x[\"distancia_min\"] > (hs_manejo*60)) \n",
    "                                                                        else x[\"duracion_min\"], \n",
    "                                                                        axis=1)\n",
    "        \n",
    "        subzonas_algoritmico_loop[\"duracion_max\"] = ((subzonas_algoritmico_loop[\"distancia_max\"]/vel_min)*60)\n",
    "        subzonas_algoritmico_loop[\"duracion_max\"] += subzonas_algoritmico_loop.apply(lambda x:  ((x[\"duracion_max\"])/hs_manejo)*hs_descanso\n",
    "                            if (x[\"distancia_max\"] > (hs_manejo*60))\n",
    "                            else x[\"duracion_max\"],\n",
    "                            axis=1)\n",
    "        \n",
    "        subzonas_algoritmico_loop.loc[subzonas_algoritmico_loop.duracion_min < 14 ,\"duracion_min\"] = 15 \n",
    "        subzonas_algoritmico_loop [\"ic_hs_min\"] = subzonas_algoritmico_loop[\"duracion_min\"].apply(lambda x:  ic_to_horas(x) )\n",
    "        subzonas_algoritmico_loop [\"ic_hs_max\"] = subzonas_algoritmico_loop[\"duracion_max\"].apply(lambda x:   ic_to_horas(x) )\n",
    "        subzonas_algoritmico_loop = subzonas_algoritmico_loop[[\"zone\", \"area\", \"ic_hs_min\",\"ic_hs_max\"]]\n",
    "        subzonas_algoritmico_loop.columns = [\"Zona\", \"Area\", \"T.T Min\", \"T.T Max\"]\n",
    "        \n",
    "        # Agrego el resultado de esta ejecucion del loop en el diccionario.\n",
    "        df_subzonas_algoritmico_dict[str(i)] = subzonas_algoritmico_loop\n",
    "except Exception as ex:\n",
    "    logger.warning(\"Error al calcular min max algoritmico por zona\")\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora voy a imputar valores que pudieran haber quedado en nulo ya que no se tenia los datos suficientes como para poder obtener el TT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo una funcion para imputar los valores de TT min y max segun el metodo algoritmico.\n",
    "# Se hace asi ya que hay valores que no pudieron ser calculados por falta de datos.\n",
    "def imputacion_confianza_nueva_zona (df_confianza, df_algoritmico):\n",
    "    # Obtengo las zonas con confianza nueva\n",
    "    mask_zonas_nuevas = df_confianza['Confianza'] == 'Nuevo'\n",
    "    lista_zonas_nuevas = df_confianza.loc[mask_zonas_nuevas, 'zone']\n",
    "    \n",
    "    # Itero por cada una de esas zonas\n",
    "    for zona_nueva in lista_zonas_nuevas:\n",
    "        # Creo mascaras para considerar la zona del loop en ambos dfs.\n",
    "        mask_zona_confianza = df_confianza['zone'] == zona_nueva\n",
    "        mask_zona_algoritmico = df_algoritmico['Zona'] == zona_nueva\n",
    "        \n",
    "        # imputo valores para esa zona.\n",
    "        df_confianza.loc[mask_zona_confianza, ['ic_min_hs', 'ic_max_hs']] = df_algoritmico.loc[mask_zona_algoritmico, ['T.T Min', 'T.T Max']].values\n",
    "    return df_confianza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hago lo mismo pero para imputar segun establecimiento.\n",
    "def imputacion_confianza_nuevo_establecimiento (df_confianza, df_algoritmico):\n",
    "    # Obtengo los establecimeintos con confianza nueva\n",
    "    mask_establecimientos_nuevos = df_confianza['Confianza'] == 'Nuevo'\n",
    "    lista_establecimientos_nuevos = df_confianza.loc[mask_establecimientos_nuevos, 'Establecimiento']\n",
    "    \n",
    "    cols_sobreescribir = ['Zona', 'T.T Min', 'T.T Max']\n",
    "    # Itero por cada uno de estos establecimientos.\n",
    "    for establecimiento in lista_establecimientos_nuevos:\n",
    "        # Creo mascaras para seleccionar el establecimiento de ambos dfs.\n",
    "        mask_establecimiento_confianza = df_confianza['Establecimiento'] == establecimiento\n",
    "        mask_establecimiento_algoritmico = df_algoritmico['Establecimiento'] == establecimiento\n",
    "        \n",
    "        # Imputo valores.\n",
    "        df_confianza.loc[mask_establecimiento_confianza, cols_sobreescribir] = df_algoritmico.loc[mask_establecimiento_algoritmico, cols_sobreescribir].values\n",
    "    return df_confianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,2):\n",
    "    # Imputo Zonas\n",
    "    df_subzonas_dict[str(i)] = imputacion_confianza_nueva_zona(df_subzonas_dict[str(i)], df_subzonas_algoritmico_dict[str(i)])\n",
    "\n",
    "    # Imputo Establecimientos\n",
    "    df_establecimiento_dict[str(i)] = imputacion_confianza_nuevo_establecimiento(df_establecimiento_dict[str(i)] , df_subzonas_2_dict[str(i)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenacion de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subzonas = pd.concat([df_subzonas_dict['0'], df_subzonas_dict['1']], ignore_index=True)\n",
    "df_establecimiento = pd.concat([df_establecimiento_dict['0'], df_establecimiento_dict['1']], ignore_index=True)\n",
    "df_subzonas_2 = pd.concat([df_subzonas_2_dict['0'], df_subzonas_2_dict['1']], ignore_index=True)\n",
    "subzonas_algoritmico = pd.concat([df_subzonas_algoritmico_dict['0'], df_subzonas_algoritmico_dict['1']], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Output\")\n",
    "def output_writer (output_name, sheet_names, df, title):\n",
    "    \"\"\"\n",
    "    Descripcion\n",
    "    -------------------------------------------------------\n",
    "    Funcion que da un formato de tabla prefinido para excel\n",
    "    \n",
    "    Parametros\n",
    "    ------------------------------------------------------\n",
    "    output_name = str, Path del archivo\n",
    "    sheet_names = list, Nombres de las hojas 1 por DataFrame\n",
    "    df = list, DataFrame para guardar\n",
    "    title = list, Titulos de cada hoja\n",
    "    \"\"\"\n",
    "    result = 'Exito al Guardar'\n",
    "    try:\n",
    "        writer = pd.ExcelWriter(output_name, engine = \"xlsxwriter\")\n",
    "\n",
    "        for i in range(len(df)):\n",
    "            df[i].to_excel(writer, sheet_name=sheet_names[i], startrow=2, header=False, index=False)\n",
    "\n",
    "            workbook = writer.book\n",
    "            worksheet = writer.sheets[sheet_names[i]]\n",
    "\n",
    "            max_row, max_col = df[i].shape\n",
    "\n",
    "            header_format = workbook.add_format({'font_name' : 'Times New Roman',\n",
    "                                                 'bold': True, \n",
    "                                                 'font_color': 'black',\n",
    "                                                 'font_size' : 14,\n",
    "                                                 'align' : 'center',\n",
    "                                                 'valign' : 'vcenter',\n",
    "                                                 'border' : 1\n",
    "                                                })\n",
    "\n",
    "            cell_format = workbook.add_format({'font_name' : 'Times New Roman',\n",
    "                                               'font_color' : 'black',\n",
    "                                               'font_size' : 12,\n",
    "                                               'align' : 'center',\n",
    "                                               'valign' : 'vcenter',\n",
    "                                              })\n",
    "\n",
    "            title_format = workbook.add_format({'font_name' : 'Times New Roman',\n",
    "                                          'bold': True, \n",
    "                                          'font_color': 'black',\n",
    "                                          'font_size' : 14,\n",
    "                                          'align' : 'center',\n",
    "                                          'valign' : 'vcenter',\n",
    "                                          'border' : 1,\n",
    "                                          'bg_color' : \"#4F81BD\"\n",
    "                                                })\n",
    "\n",
    "            columns_settings = [{'header': column, \n",
    "                                 'header_format': header_format\n",
    "                                } for column in df[i].columns]\n",
    "\n",
    "            worksheet.add_table(1, 0, max_row+1, max_col - 1, {'columns': columns_settings\n",
    "                                                                })\n",
    "            worksheet.set_column(first_col = 0, last_col = max_col -1 , width = 15, cell_format = cell_format)\n",
    "\n",
    "            worksheet.set_row (1,30)\n",
    "\n",
    "            worksheet.merge_range(0,0,0,max_col-1, title[i],title_format)\n",
    "            worksheet.set_row (0,30)\n",
    "\n",
    "        #writer.save()\n",
    "        writer.close()\n",
    "    except Exception as ex:\n",
    "        result = 'Error al Guardar'+ str(ex.__class__) \n",
    "        logger.warning(\"Error al guardar archivos de salida\",exc_info=True)\n",
    "\n",
    "    print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen_segmentacion[\"Duracion Minima\"] = resumen_segmentacion[\"Duracion Minima\"].apply(lambda x: min_to_horas(x))\n",
    "resumen_segmentacion[\"Duracion Maxima\"] = resumen_segmentacion[\"Duracion Maxima\"].apply(lambda x: min_to_horas(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formateo del output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a separar la letra de las zonas de el numero de la subzona clusterizada\n",
    "# si es que se clusterizo. \n",
    "df_subzonas = df_subzonas [[\"subZone\",\"area\",\"ic_min_hs\",\"ic_max_hs\",\"Confianza\"]].copy()\n",
    "\n",
    "# Creo patron para detectar si la zona cuenta con un numero que indica la subzona.\n",
    "pattern = r'[a-zA-Z]\\d'\n",
    "\n",
    "# Booleano que detecta la presencia de numeros en la zona.\n",
    "condition_subzones = df_subzonas['subZone'].str.contains(pattern).any()\n",
    "\n",
    "# Si la zona esta clusterizada.\n",
    "if condition_subzones:\n",
    "    # Separo letras de numeros\n",
    "    df_subzonas[['zone', 'subZone']] = df_subzonas['subZone'].str.extract(r'([A-Z]+)(\\d*)')\n",
    "    # Reordeno DF.\n",
    "    df_subzonas = df_subzonas[['zone', 'subZone', 'area', 'ic_min_hs', 'ic_max_hs', 'Confianza']]\n",
    "    # Reemplazo valores vacios.\n",
    "    df_subzonas['subZone'].replace('', '-', inplace=True)\n",
    "    # Cambio de nombre las columnas.\n",
    "    df_subzonas.columns = [\"Zona\",\"SubZona\", \"Area\", \"T.T Min\", \"T.T Max\",\"Confianza\"]\n",
    "else:\n",
    "    # Si no se detecta la presencia de numeros en la zona.\n",
    "    df_subzonas.columns = [\"Zona\",\"Area\", \"T.T Min\", \"T.T Max\",\"Confianza\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hago lo mismo para el modelo algoritmico.\n",
    "# Booleano que detecta la presencia de numeros en la zona.\n",
    "subzonas_algoritmico = subzonas_algoritmico.copy() # Para error de copia.\n",
    "\n",
    "condition_subzones = subzonas_algoritmico['Zona'].str.contains(pattern).any()\n",
    "\n",
    "# Si la zona esta clusterizada.\n",
    "if condition_subzones:\n",
    "    # Separo letras de numeros\n",
    "    subzonas_algoritmico[['zone', 'subZone']] = subzonas_algoritmico['Zona'].str.extract(r'([A-Z]+)(\\d*)')\n",
    "    # Reordeno DF.\n",
    "    subzonas_algoritmico = subzonas_algoritmico[['zone', 'subZone', 'Area', 'T.T Min', 'T.T Max']]\n",
    "    # Reemplazo valores vacios.\n",
    "    subzonas_algoritmico['subZone'].replace('', '-', inplace=True)\n",
    "    # Cambio de nombre las columnas.\n",
    "    subzonas_algoritmico.columns = [\"Zona\",\"SubZona\",\"Area\",\"T.T Min\", \"T.T Max\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora por establecimiento.\n",
    "df_establecimiento = df_establecimiento.copy() # Para error de copia.\n",
    "# Booleano que detecta la presencia de numeros en la zona.\n",
    "condition_subzones = df_establecimiento['Zona'].str.contains(pattern).any()\n",
    "\n",
    "# Si la zona esta clusterizada.\n",
    "if condition_subzones:\n",
    "    # Separo letras de numeros\n",
    "    df_establecimiento[['zone', 'subZone']] = df_establecimiento['Zona'].str.extract(r'([A-Z]+)(\\d*)')\n",
    "    # Reordeno DF.\n",
    "    df_establecimiento = df_establecimiento[[\n",
    "        'zone', \n",
    "        'subZone', \n",
    "        'Establecimiento', \n",
    "        'Good Supplier', \n",
    "        'Area', \n",
    "        'T.T Min', \n",
    "        'T.T Max', \n",
    "        'Confianza', \n",
    "        'Descanso'\n",
    "        ]]\n",
    "    \n",
    "    # Reemplazo valores vacios.\n",
    "    df_establecimiento['subZone'].replace('', '-', inplace=True)\n",
    "    # Cambio de nombre las columnas.\n",
    "    df_establecimiento.rename(columns={'zone' : 'Zona', 'subZone' : 'SubZona'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora por establecimiento del modelo constante.\n",
    "df_subzonas_2 = df_subzonas_2.copy() # Para error de copia.\n",
    "# Booleano que detecta la presencia de numeros en la zona.\n",
    "condition_subzones = df_subzonas_2['Zona'].str.contains(pattern).any()\n",
    "\n",
    "# Si la zona esta clusterizada.\n",
    "if condition_subzones:\n",
    "    # Separo letras de numeros\n",
    "    df_subzonas_2[['zone', 'subZone']] = df_subzonas_2['Zona'].str.extract(r'([A-Z]+)(\\d*)')\n",
    "    # Reordeno DF.\n",
    "    df_subzonas_2 = df_subzonas_2[[\n",
    "        'zone', \n",
    "        'subZone', \n",
    "        'Establecimiento', \n",
    "        'Good Supplier', \n",
    "        'Area', \n",
    "        'T.T Min', \n",
    "        'T.T Max', \n",
    "        'Descanso'\n",
    "        ]]\n",
    "    \n",
    "    # Reemplazo valores vacios.\n",
    "    df_subzonas_2['subZone'].replace('', '-', inplace=True)\n",
    "    # Cambio de nombre las columnas.\n",
    "    df_subzonas_2.rename(columns={'zone' : 'Zona', 'subZone' : 'SubZona'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora vamos a formatear el Df de informacionde establecimientos.\n",
    "\n",
    "# Booleano que detecta la presencia de numeros en la zona.\n",
    "condition_subzones = df_distancias['zone'].str.contains(pattern).any()\n",
    "\n",
    "# Si la zona esta clusterizada.\n",
    "if condition_subzones:\n",
    "    # Separo letras de numeros\n",
    "    df_distancias[['zone', 'subZone']] = df_distancias['zone'].str.extract(r'([A-Z]+)(\\d*)')\n",
    "    # Reemplazo valores vacios.\n",
    "    df_distancias['subZone'].replace('', '-', inplace=True)\n",
    "    # Selecciono columnas.\n",
    "    df_distancias = df_distancias [[\n",
    "        'establecimiento',\n",
    "        'zone',\n",
    "        'subZone',\n",
    "        'good_supplier',\n",
    "        'area',\n",
    "        \"state\",\n",
    "        \"city\",\n",
    "        \"latitud\",\n",
    "        \"longitud\",\n",
    "        \"distancia\",\n",
    "        \"duracion\",\n",
    "        \"duracion_cdescanso\"\n",
    "    ]]\n",
    "    # Renombro zonas.\n",
    "    df_distancias.columns = [\n",
    "        'Establecimiento',\n",
    "        \"Zona\",\n",
    "        'SubZona',\n",
    "        'Good Supplier',\n",
    "        'Area',\n",
    "        'Provincia',\n",
    "        'Ciudad',\n",
    "        'Latitud',\n",
    "        'Longitud',\n",
    "        'Distancia a Planta',\n",
    "        'Duracion Google',\n",
    "        'Descanso'\n",
    "    ]\n",
    "else:\n",
    "    # Si no se detecta la presencia de numeros en la zona.\n",
    "    df_distancias = df_distancias [[\n",
    "        \"establecimiento\",\n",
    "        \"zone\",\n",
    "        'good_supplier',\n",
    "        'area',\n",
    "        \"state\",\n",
    "        \"city\",\n",
    "        \"latitud\",\n",
    "        \"longitud\",\n",
    "        \"distancia\",\n",
    "        \"duracion\",\n",
    "        \"duracion_cdescanso\"\n",
    "    ]]\n",
    "\n",
    "    df_distancias.columns = [\n",
    "        \"Establecimiento\",\n",
    "        \"Zona\",\n",
    "        'Good Supplier',\n",
    "        'Area',\n",
    "        \"Provincia\",\n",
    "        \"Ciudad\",\n",
    "        \"Latitud\",\n",
    "        \"Longitud\",\n",
    "        \"Distancia a Planta\",\n",
    "        \"Duracion Google\",\n",
    "        \"Descanso\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLevo los nombres de los establecimientos a mayuscula.\n",
    "df_establecimiento['Establecimiento'] = df_establecimiento['Establecimiento'].apply(lambda x: x.title())\n",
    "df_subzonas_2['Establecimiento'] = df_subzonas_2['Establecimiento'].apply(lambda x: x.title())\n",
    "df_distancias['Establecimiento'] = df_distancias['Establecimiento'].apply(lambda x: x.title())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecha = str(date.today())\n",
    "dir_out = \"Output\"\n",
    "existe_directorio = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exito al Guardar\n",
      "Exito al Guardar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TALIGENT\\anaconda3\\envs\\transit_time_bayer\\lib\\site-packages\\xlsxwriter\\worksheet.py:3261: UserWarning: Must have at least one data row in in add_table()\n",
      "  warn(\"Must have at least one data row in in add_table()\")\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for directorio in os.listdir(dir_out):\n",
    "        if directorio == fecha:\n",
    "            existe_directorio = True\n",
    "            dir_out = os.path.join (dir_out,fecha)\n",
    "            break\n",
    "    if existe_directorio == False:\n",
    "        dir_out = os.path.join (dir_out,fecha)\n",
    "        os.mkdir(dir_out)\n",
    "\n",
    "    last = 0\n",
    "    output_name = \"\"\n",
    "    if (len (os.listdir(dir_out)) == 0):\n",
    "        output_name = fecha+\"-\"+\"ESTIMACIONTTMINMAX_0.xlsx\"\n",
    "    else:\n",
    "        for file in os.listdir(dir_out):\n",
    "            if file != ('.ipynb_checkpoints'):\n",
    "                num = int(file.split(\"_\")[1].split(\".\")[0])\n",
    "                if num > last:\n",
    "                    last = num\n",
    "        output_name = fecha+\"-\"+\"ESTIMACIONTTMINMAX_{:d}\".format(last+1)+'.xlsx'\n",
    "    output_name = os.path.join(dir_out,output_name)\n",
    "\n",
    "    os.listdir(dir_out)\n",
    "\n",
    "    dfs = [\n",
    "        df_subzonas,\n",
    "        subzonas_algoritmico,\n",
    "        df_establecimiento,\n",
    "        df_subzonas_2,\n",
    "        df_distancias,\n",
    "        resumen_segmentacion,\n",
    "        df_maestro_establecimientos\n",
    "    ]\n",
    "    \n",
    "    sheet_names = [\n",
    "        \"T.T Zonas Est\",\n",
    "        \"T.T Zonas Const\",\n",
    "        \"T.T Establecimientos Est\",\n",
    "        \"T.T Establecimientos Const\",\n",
    "        \"Establecimientos\",\n",
    "        \"Segmentacion\",\n",
    "        \"Maestro\"\n",
    "    ]\n",
    "    \n",
    "    titles = [\n",
    "        \"T.T Zonas Estadistico\",\n",
    "        \"T.T Zonas Cosntante\",\n",
    "        \"T.T Establecimientos Estadistico\",\n",
    "        \"T.T Establecimientos Constante\",\n",
    "        \"Datos Establecimientos\",\n",
    "        \"Resumen Segmentacion\",\n",
    "        \"Establecimientos Historicos\"\n",
    "    ]\n",
    "    \n",
    "    output_writer(output_name,sheet_names,dfs,titles)\n",
    "\n",
    "    output_writer(os.path.join(\"Output\",\"duplicados.xlsx\"),[\"Duplicado\"],[df_duplicado],[\"Establecimientos Duplicados\"])\n",
    "\n",
    "    index_drop = df_maestro_establecimientos.loc[df_maestro_establecimientos[\"Duplicado\"]!=0].index\n",
    "    df_maestro_establecimientos.drop(index_drop,inplace=True)\n",
    "    df_maestro_establecimientos.to_excel(name_maestro_establecimientos,index=False)\n",
    "except Exception as ex:\n",
    "    logger.warning(\"Error al guardar los archivos\",exc_info=True)\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Movemos los archivos a procesados\n",
    "# try:\n",
    "#     if (hay_archivos_establecimientos_nuevo):\n",
    "#         os.rename(archivo_establecimientos_nuevo, archivo_establecimientos_nuevo.replace(\"PENDIENTE\",\"PROCESADO\"))\n",
    "\n",
    "# except Exception as ex:\n",
    "#     logger.warning(\"Error al mover los archivos a procesados.\",exc_info=True)\n",
    "#     quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ejecutamos el env√≠o por Mail\n",
    "# try:\n",
    "#     os.system(\"python Mail.py\")\n",
    "\n",
    "# except Exception as ex:\n",
    "#     logger.warning(\"Error al enviar los archivos por mail.\",exc_info=True)\n",
    "#     quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = timeit.default_timer()\n",
    "logger.info(f\"Fin de Ejecucion de ejecucion {stop-start}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
